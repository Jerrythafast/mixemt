#!/usr/bin/python
"""

mixemt (Mix + EM + mitochondrial sequence)

This script implements an approach for deconvoluting mixtures of mitochondrial
sequences based on a known phylogeny from phylotree.org and an
Expectation-Maximization approach to estimate the number and relative
abundances of contributing haplotypes. Based on this information, reads are
assigned to sub-assemblies to reconstruct the haplotypes.

Outline of approach:

1. Identify all non-reference SNP variant sites that are present in this
sample.

2. Contruct a matrix of known mtDNA variants from phylotree and associated
haplotypes from phylotree.

3. EM algorithm to estimate contributing haplotypes and abundances.

4. Output fragments by contributing haplotype.

"""

import sys
import argparse
import pysam
import numpy

import phylotree
import preprocess
import em
import assemble


def open_aln_file(sam_fn, args):
    """
    Opens the file specifed by the filename parameter and returns the
    AlignmentFile object. If the file cannot be opened, and error is printed
    and the program exits.
    """
    try:
        if sam_fn.endswith('.bam'):
            samfile = pysam.AlignmentFile(sam_fn, 'rb')
        else: # assume sam_fn.endswith('.sam'):
            samfile = pysam.AlignmentFile(sam_fn, 'r')
        if args.verbose:
            sys.stderr.write('Read %d alignments from "%s".\n' 
                             % (samfile.count(), sam_fn))
        return samfile
    except (ValueError, IOError) as inst:
        sys.stderr.write("Error: %s\n" % (inst))
        sys.exit(1)
    return


def open_phylotree(phy_fn, args):
    """
    Opens the phylotree CSV file and uses the module "phylotree" to read in
    a list of variant positions and a table of haplogroups and associated
    variants.
    """
    try:
        with open(phy_fn, 'r') as phy_in:
            var_pos, hap_var = phylotree.read_phylotree(phy_in, False, 
                                                        False, False)
            if args.verbose:
                sys.stderr.write('Using %d variant sites from %d haplogroups.\n'
                                 % (len(var_pos), len(hap_var)))
            return var_pos, hap_var 
    except (ValueError, IOError) as inst:
        sys.stderr.write("Error: %s\n" % (inst))
        sys.exit(1)
    return


def open_refseq(fa_fn, args):
    """
    Opens the FASTA formatted file specified by the fa_fn parameter and returns
    the sequence of the first entry as a string. If an error occurs an error is
    printed and the program exits.
    """
    try:
        fafile = pysam.FastaFile(fa_fn)
        if args.verbose:
            sys.stderr.write('Read reference sequence "%s" from "%s".\n' 
                             % (fafile.references[0], fa_fn))
        return fafile.fetch(fafile.references[0]).upper()
    except (ValueError, IOError) as inst:
        sys.stderr.write("Error: %s\n" % (inst))
        sys.exit(1)
    except IndexError as inst:
        sys.stderr.write('Error: no records in "%s"\n' % (fa_fn))
        sys.exit(1)
    return


def load_prev(prefix):
    """
    Loads a previously state from a series of files with the same prefix name.
    """
    try:
        haps  = list()
        reads = list()
        read_sigs = dict()
        read_wts  = list()
        with open("%s.haps" % (prefix), 'r') as hap_in:
            for line in hap_in:
                haps.append(line.rstrip())
        with open("%s.reads" % (prefix), 'r') as read_in:
            for line in read_in:
                items = line.split('\t')
                sig = items[0]
                reads.append(sig)
                read_sigs[sig] = items[1].rstrip().split(',')
                read_wts.append(len(read_sigs[sig]))
        read_hap_mat = numpy.load("%s.mat.npy" % (prefix))
        props = numpy.load("%s.prop.npy" % (prefix))
        wts = numpy.array(read_wts)
        return haps, reads, read_sigs, wts, props, read_hap_mat
    except (ValueError, IOError) as inst:
        sys.stderr.write("Error loading previous results:\n%s\n" % (inst))
        sys.exit(1)
    return


def dump_all(prefix, haps, reads, read_sigs, props, read_hap_mat):
    """
    Writes the results of the EM step to a series of files that can be loaded
    later on. Used to skip the matrix building and convergence steps when
    debugging.
    """
    try:
        with open("%s.haps" % (prefix), 'w') as hap_out:
            for hap in haps:
                hap_out.write('%s\n' % (hap))
        with open("%s.reads" % (prefix), 'w') as read_out:
            for read in reads:
                read_out.write('%s\t%s\n' % (read, ','.join(read_sigs[read])))
        numpy.save("%s.mat" % (prefix), read_hap_mat)
        numpy.save("%s.prop" % (prefix), props)
    except (ValueError, IOError) as inst:
        sys.stderr.write("Error:\n %s\n" % (inst))
    return


def process_and_report(args):
    """
    This function takes all of the input from args and runs through the steps
    of preprocessing EM and interpretation.
    """
    # Load up the data.
    refseq  = open_refseq(args.ref_fn, args)
    samfile = open_aln_file(args.sam_fn, args)
    var_pos, hap_var = open_phylotree(args.phy_fn, args)

    if args.load is not None:
        # Just load the saved results instead of running everything again.
        if args.verbose:
            sys.stderr.write('\nLoading previous results from %s.*\n'
                             % (args.load))
        haplogroups, reads, read_sigs, wts, props, read_hap_mat = \
            load_prev(args.load)

        if args.verbose:
            sys.stderr.write('Considering %d fragments '
                             '(%d distinct sub-haplotypes)\n\n'
                             % (numpy.sum(wts), len(reads)))
    else:
        # Build input for EM step
        em_mat, wts, haplogroups, reads, read_sigs = \
            preprocess.build_em_input(samfile, refseq, var_pos, hap_var, args)

        # Run EM
        props, read_hap_mat = em.run_em(em_mat, wts, args.n_multi,
                                        init_alpha=args.init_alpha,
                                        max_iter=10000, 
                                        tolerance=args.tolerance,
                                        verbose=args.verbose)

        # Save the results if requested.
        if args.save is not None:
            sys.stderr.write('\nSaving results to %s.*\n\n'
                             % (args.save))
            dump_all(args.save, haplogroups, reads,
                     read_sigs, props, read_hap_mat)

    contribs = assemble.get_contributors(haplogroups, props, read_hap_mat, 
                                         args.min_prob, args.min_reads)
    contrib_reads = assemble.assign_reads(contribs, haplogroups, reads, 
                                      read_hap_mat, args.min_prob)
 
    # Report the results
    if args.verbose:
        assemble.report_top_props(haplogroups, props, 10)
        assemble.report_read_votes(haplogroups, read_hap_mat, 10)

    assemble.report_contributors(sys.stdout, contribs, contrib_reads, wts)
   
    if args.out_prefix is not None:
        return assemble.write_haplotypes(samfile, contrib_reads, reads, 
                                         read_sigs, args.out_prefix, 
                                         args.verbose)
    return 0


def main():
    """ Reads input filenames from command line args and processes input
        through the analysis steps """
    parser = argparse.ArgumentParser("Estimates the number and proportions of "
                                     "contributing haplotypes.")
    parser.add_argument("ref_fn", metavar="ref.fasta", type=str,
                        help="FASTA file contain the reference sequence.")
    parser.add_argument("phy_fn", metavar="phylotree.csv", type=str,
                        help="Phylotree CSV file")
    parser.add_argument("sam_fn", metavar="reads.[sb]am", type=str,
                        help="Aligned reads in SAM/BAM format.")
    parser.add_argument('-q', '--min-MQ', dest='min_mq', type=int,
                        metavar="INT", default=30,
                        help="Skip alignments with mapQ < INT")
    parser.add_argument('-Q', '--min-BQ', dest='min_bq', type=int,
                        metavar="INT", default=30,
                        help="Skip bases with baseQ < INT")
    parser.add_argument('-i', '--init', dest='init_alpha', type=float,
                        default=1.0, metavar="ALPHA",
                        help="Use parameter ALPHA to initialize haplogroup "
                             "contributions from Dirichlet distribution.")
    parser.add_argument('-c', '--converge', dest='tolerance', type=float,
                        default=0.0001, metavar="TOLERANCE",
                        help="Stop EM iteration when abs. difference between "
                             "current and previous contribution estimates is "
                             "< TOLERANCE.")
    parser.add_argument('-m', '--multi-em', dest='n_multi', type=int,
                        default=1, metavar="N",
                        help="Runs EM until convergence multiple times and "
                             "reports the results average over all runs.")
    parser.add_argument('-l', '--load', dest='load', type=str,
                        default=None, metavar='PREFIX',
                        help="Skip EM step and load from a previous result "
                             "(overrides -s).")
    parser.add_argument('-s', '--save', dest='save', type=str,
                        default=None, metavar='PREFIX',
                        help="Save the EM results using this file prefix.")
    parser.add_argument('-p', '--prob', dest='min_prob', type=float,
                        default=0.95,
                        help='Minimum probability required to assign read to '
                             'a contributing haplogroup.')
    parser.add_argument('-r', '--min-reads', dest='min_reads', type=int,
                        default=1, metavar='N',
                        help="Haplogroup must have N reads to be considered "
                             "a contributor.")
    parser.add_argument('-o', '--out', dest='out_prefix', type=str,
                        default=None, metavar='PREFIX',
                        help="If set, write assigned reads to contributor-"
                             "specific SAM/BAM files using this "
                             "filename prefix")
    parser.add_argument('-v', '--verbose', action="store_true",
                        help="Print detailed status while running.")
    args = parser.parse_args()
    
    if args.verbose:
        sys.stderr.write('%s\n\n' % (' '.join(sys.argv)))

    return process_and_report(args)


if __name__ == "__main__":
    sys.exit(main())
